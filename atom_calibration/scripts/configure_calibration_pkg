#!/usr/bin/env python3

# stdlib
import os
import sys
import argparse
import subprocess
from os.path import exists
from copy import deepcopy
from datetime import date, datetime

import matplotlib
import atom_core.config_io
import atom_core.drawing

# 3rd-party
import yaml
import numpy
import rospy
import rospkg
import rosbag
import jinja2
import matplotlib.pyplot as plt
import networkx as nx

# local packages
import atom_core.utilities as utilities
from colorama import Style, Fore
from graphviz import Digraph
from urdf_parser_py.urdf import URDF
from matplotlib import cm
from jinja2 import Environment, FileSystemLoader

if __name__ == "__main__":
    # Parse command line arguments
    ap = argparse.ArgumentParser()
    ap.add_argument("-n", "--name", help='package name', type=str, required=True)
    ap.add_argument("-utf", "--use_tfs", action="store_true",
                    help='Use transformations in the bag file instead of generating new tfs from the xacro, '
                         'joint_state_msgs and robot state publisher.')
    ap.add_argument(
        "-cfg", "--config_file",
        help='Specify if you want to configure the calibration package with a specific configutation file. If this flag is not given, the standard config.yml ill be used.',
        type=str, required=False)
    args = vars(ap.parse_args())

    # --------------------------------------------------------------------------
    # Initial setup
    # --------------------------------------------------------------------------
    package_name = os.path.basename(args['name'])
    rospack = rospkg.RosPack()
    atom_calibration_path = rospack.get_path('atom_calibration')

    # Check if package is under $ROS_PACKAGE_PATH, abort if not
    assert (package_name in rospack.list()), \
        Fore.YELLOW + package_name + ' not found under ROS. Are you sure the path you gave in under your ' \
                                     '$ROS_PACKAGE_PATH? Calibration package will not work if it is not under the ' \
                                     '$ROS_PACKAGE_PATH. Please fix this before running the package configuration. ' \
        + Style.RESET_ALL

    package_path = rospack.get_path(package_name)  # full path to the package, including its name.
    package_base_path = os.path.dirname(package_path)  # parent path where the package is located

    rviz_file_template = atom_calibration_path + '/templates/config.rviz'
    rviz_set_initial_estimate = 'set_initial_estimate.rviz'
    rviz_collect_data = 'collect_data.rviz'
    rviz_calibrate = 'calibrate.rviz'
    rviz_dataset_playback = 'dataset_playback.rviz'
    set_initial_estimate_launch_file = package_path + '/launch/set_initial_estimate.launch'
    data_collection_launch_file = package_path + '/launch/collect_data.launch'
    calibrate_launch_file = package_path + '/launch/calibrate.launch'
    dataset_playback_launch_file = package_path + '/launch/dataset_playback.launch'

    # Template engine1 setup
    file_loader = FileSystemLoader(atom_calibration_path + '/templates')
    env = Environment(loader=file_loader, undefined=jinja2.StrictUndefined)
    env.add_extension('jinja2.ext.do')

    # Date
    dt_string = datetime.now().strftime("%d/%m/%Y %H:%M:%S")

    # --------------------------------------------------------------------------
    # Read the config.yml file
    # --------------------------------------------------------------------------
    print(args['config_file'])
    # config_file = package_path + '/calibration/config.yml'

    if not args['config_file']:
        config_file = package_path + '/calibration/config.yml'
    else:
        config_file = package_path + '/calibration/' + args['config_file']
        if not exists(config_file):
            config_file = package_path + '/calibration/config.yml'
    print('Loading config file ' + config_file)

    config = atom_core.config_io.loadConfig(config_file)

    # print('Loading config file ' + config_file)
    # config = atom_core.config_io.loadConfig(config_file)

    # Sensors colormap. Access with:  color_map_sensors[idx, :]
    cm_sensors = cm.Set3(numpy.linspace(0, 1, len(config['sensors'].keys())))
    # --------------------------------------------------------------------------
    # Setup the description file
    # --------------------------------------------------------------------------
    description_file, _, _ = atom_core.config_io.uriReader(config['description_file'])
    description_file_out_initial_estimate = package_path + '/urdf/initial_estimate.urdf.xacro'
    atom_core.config_io.execute('cp ' + description_file + ' ' + description_file_out_initial_estimate,
                                verbose=False)  # Copy the xacro to the initial_estimate file

    # --------------------------------------------------------------------------
    # Read the bag file
    # --------------------------------------------------------------------------
    bag_file, _, bag_file_rel = atom_core.config_io.uriReader(config['bag_file'])
    print('Loading bagfile ' + bag_file)
    bag = rosbag.Bag(bag_file)
    bag_info = bag.get_type_and_topic_info()
    bag_types = bag_info[0]
    bag_topics = bag_info[1]
    # print('\n' + str(bag_topics))

    # for topic, msg, t in bag.read_messages(topics=['chatter', 'numbers']):
    #     print(msg)
    bag.close()

    # --------------------------------------------------------------------------
    # Read the description.urdf.xacro file
    # --------------------------------------------------------------------------
    # Check the description file
    urdf_file = '/tmp/description.urdf'
    if os.path.exists(urdf_file):
        print('Deleting temporary file ' + urdf_file)
        os.remove(urdf_file)

    print('Parsing description file ' + description_file)
    atom_core.config_io.execute('xacro ' + description_file + ' -o ' + urdf_file, verbose=True)  # create tmp urdf file
    try:
        description = URDF.from_xml_file(urdf_file)  # read the urdf file
    except:
        atom_core.config_io.execute('xacro ' + description_file + ' -o ' + urdf_file,
                                    verbose=True)  # print xacro parsing
        raise ValueError('Could not parse description file ' + description_file)

    # --------------------------------------------------------------------------
    # Create a tf graph to support verifications
    # --------------------------------------------------------------------------
    if not args['use_tfs']:  # create a graph using the information in the urdf
        print('Creating transformation tree using the urdf robot description ...')
        gx = nx.DiGraph()

        for link in description.links:  # A graph node for each link in the urdf
            gx.add_node(link.name)
            print(link.name)

        for joint in description.joints:  # atomic transformations are given by the joints
            if joint.type == 'fixed':
                gx.add_edge(joint.parent, joint.child, weight=1, type='static')
            else:
                gx.add_edge(joint.parent, joint.child, weight=1, type='dynamic')
    else:
        print('Creating transformation tree using the tfs in the bagfile ...')
        gx = nx.DiGraph()

        print('Loading bagfile ' + bag_file)
        bag = rosbag.Bag(bag_file)

        for topic, msg, t in bag.read_messages(topics=['/tf']):
            for transform in msg.transforms:
                if not gx.has_edge(transform.header.frame_id, transform.child_frame_id):
                    gx.add_edge(transform.header.frame_id, transform.child_frame_id, weight=1, type='dynamic')

        for topic, msg, t in bag.read_messages(topics=['/tf_static']):
            for transform in msg.transforms:
                if not gx.has_edge(transform.header.frame_id, transform.child_frame_id):
                    gx.add_edge(transform.header.frame_id, transform.child_frame_id, weight=1, type='static')

        bag.close()
        # nx.draw(gx, with_labels=True)
        # plt.show()

    # --------------------------------------------------------------------------
    # Verifications: Run as much as we can think of to see if something is wrong. Better early than late.
    # --------------------------------------------------------------------------
    print('Running verifications ... please wait ...')

    compressed_topics = {}  # a list of compressed topics to decompress in the launch file
    # Check if config sensor topics exist in the bag file
    for sensor_key in config['sensors']:
        topic = config['sensors'][sensor_key]['topic_name']
        if topic not in bag_topics:

            topic_compressed = topic + '/compressed'
            if topic_compressed in bag_topics:  # Check if the topic is a compressed image topic
                msg_type = bag_info[1][topic_compressed].msg_type
                if msg_type == 'sensor_msgs/CompressedImage':  # Check if the topic of correct msg_type
                    compressed_topics[topic] = {'topic_compressed': topic_compressed, 'msg_type': msg_type,
                                                'sensor_key': sensor_key}
                    print(Fore.BLUE + 'Topic ' + topic + ' is in compressed format (' + topic_compressed +
                          '). Will setup a decompressor.' + Style.RESET_ALL)
                else:
                    raise ValueError(Fore.RED + ' Topic ' + topic + ' (from sensor ' + sensor_key +
                                     ') exists in compressed format in the bag file, but is not of msg_type '
                                     '"sensor_msgs/CompressedImage"' + Style.RESET_ALL)
            else:

                raise ValueError(Fore.RED + ' Topic ' + topic + ' (from sensor ' + sensor_key +
                                 ') does not exist in the bag file.' + Style.RESET_ALL)

    throttle_topics = {}
    use_throttle_topics = {}
    for sensor_key in config['sensors']:
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        if topic_compressed in bag_topics:  # Check if the topic is a compressed image topic
            topic = topic_compressed
        if 'throttle' in config['sensors'][sensor_key]:
            throttle = config['sensors'][sensor_key]['throttle']
            print('Sensor ' + sensor_key + ' has throttle')

            use_throttle = True
        else:
            print('Sensor ' + sensor_key + ' does not have throttle')
            throttle = None
            use_throttle = False
        # else:

        throttle_topics[topic] = {'throttled_topic': topic, 'sensor_key': sensor_key, 'use_throttle': use_throttle,
                                  'throttle_hz': throttle}

    # Verify consistency of the tf tree
    frames_to_verify = {'world_link': config['world_link'],
                        'calibration_pattern.pattern_link': config['calibration_pattern']['parent_link']}
    for sensor_key in config['sensors']:  # Check if link, child_link and parent_link exist in the bagfile.
        for frame in ['child_link', 'parent_link', 'link']:
            frames_to_verify[sensor_key + '.' + frame] = config['sensors'][sensor_key][frame]

    print('Checking if all tf frames exist ...')
    print(frames_to_verify)
    for key, frame in frames_to_verify.items():
        if not frame in gx:
            raise ValueError('Error: frame ' + Fore.RED + frame + Style.RESET_ALL + ' given in config file for ' +
                             Fore.BLUE + key + Style.RESET_ALL + ' does not exist. Check config file ' +
                             Fore.BLUE + config_file + Style.RESET_ALL)

    # if nx.is_connected(gx):
    if nx.is_weakly_connected(gx):
        print('TF tree is connected.')
    else:
        pos = nx.random_layout(gx)
        edges, weights = zip(*nx.get_edge_attributes(gx, 'weight').items())
        edge_labels = nx.draw_networkx_edge_labels(gx, pos)
        nx.draw(gx, with_labels=True)
        plt.show()
        raise ValueError('TF tree is not connected. Aborting.')

    # Pretty print of transformation chains
    # TODO How to detect a dynamic transformation using the information in the bagfile's tfs?
    print(
        'Transformations for sensors. Color coding is ' + Fore.RED + 'root link' + Fore.RESET + ', ' + Fore.BLUE + 'to be calibrated'
        + Fore.RESET + ', ' + Fore.GREEN + 'dynamic transformation' + Fore.RESET + ', ' + Fore.LIGHTMAGENTA_EX +
        'sensor data frame' + Fore.RESET + '.')
    for sensor_key, sensor in config['sensors'].items():
        paths = nx.shortest_path(gx, config['world_link'], sensor['link'])  # path between root and sensor data frame
        print('Path from ' + Fore.RED + config['world_link'] + Fore.RESET + ' to sensor ' + Fore.LIGHTMAGENTA_EX +
              sensor_key + Fore.RESET + ':')
        s = '['
        for path in paths:
            if path == config['world_link']:
                s += Fore.RED + path + Fore.RESET + ', '
            elif path == sensor['parent_link'] or path == sensor['child_link']:
                s += Fore.BLUE + path + Fore.RESET + ', '
            elif path == sensor['link']:
                s += Fore.LIGHTMAGENTA_EX + path + Fore.RESET + ', '
            else:
                for joint in description.joints:  # atomic transformations are given by the joints
                    if path == joint.parent or path == joint.child:
                        if joint.type == 'fixed':
                            s += path + ', '
                        else:
                            s += Fore.GREEN + path + Fore.RESET + ', '
                        break
        s = s[:-2]
        s += ']'
        print(s)

    # --------------------------------------------------------------------------
    # Create dot calibration graph (used for printing out a summary)
    # --------------------------------------------------------------------------
    g = Digraph('G', filename='summary', directory='/tmp/', graph_attr={'title': 'graph'})  # create a graph

    for link in gx.nodes:  # A graph node for each link in the urdf
        rgb = matplotlib.colors.rgb2hex([0, 0, 0])  # black by default
        label = link
        if config['world_link'] == link:
            label += '\n(world link)'
            rgb = matplotlib.colors.rgb2hex([1, 0, 0])

        for sensor_key, sensor in config['sensors'].items():
            if sensor['link'] == link:
                label += '\n(data from sensor ' + sensor_key + ')'
                rgb = matplotlib.colors.rgb2hex([0, 0.5, 0])

        g.node(link, label=label, _attributes={'penwidth': '2', 'color': rgb}, )

    for parent, child, edge_data in gx.edges(data=True):  # atomic transformations are given by the joints
        label = ''
        type = edge_data['type']
        rgb = matplotlib.colors.rgb2hex([0, 0, 0])  # black by default
        for sensor_key, sensor in config['sensors'].items():  # if the joint is marked for calibration
            if sensor['parent_link'] == parent and sensor['child_link'] == child:
                label += 'To be calibrated\n'
                rgb = matplotlib.colors.rgb2hex([0, 0, 1])

        label += type

        g.edge(parent, child, color=rgb, style='solid', _attributes={'penwidth': '1', 'fontcolor': rgb},
               label=label)

    # g.view()
    g.render(filename='summary', directory=package_path + '/calibration', cleanup=True)

    # --------------------------------------------------------------------------
    # Create the playback launch file
    # --------------------------------------------------------------------------
    playbag_launch_file = package_path + '/launch/playbag.launch'
    print('Setting up ' + playbag_launch_file + ' ...')

    template = env.get_template('playbag.launch')
    with open(playbag_launch_file, 'wb') as f:
        output = template.render(c={'filename': os.path.basename(playbag_launch_file),
                                    'date': dt_string,
                                    'bag_file': bag_file_rel,
                                    'use_tfs': args['use_tfs'],
                                    'package_name': package_name,
                                    'rviz_set_initial_estimate': rviz_set_initial_estimate,
                                    'use_compressed_topics': bool(compressed_topics),
                                    'compressed_topics': compressed_topics,
                                    'throttle_topics': throttle_topics
                                    })
        f.write(output.encode('utf-8'))

    # --------------------------------------------------------------------------
    # Create the set_initial_estimate launch file
    # --------------------------------------------------------------------------
    launch_file = set_initial_estimate_launch_file
    print('Setting up ' + launch_file + ' ...')

    template = env.get_template(os.path.basename(launch_file))
    with open(launch_file, 'wb') as f:
        output = template.render(c={'filename': os.path.basename(launch_file),
                                    'date': dt_string,
                                    'package_name': package_name,
                                    'rviz_set_initial_estimate': rviz_set_initial_estimate,
                                    'bag_file': bag_file_rel,
                                    'marker_size': 0.5
                                    })
        f.write(output.encode('utf-8'))

    # --------------------------------------------------------------------------
    # Create the data collection launch file
    # --------------------------------------------------------------------------
    launch_file = data_collection_launch_file
    print('Setting up ' + launch_file + ' ...')

    template = env.get_template(os.path.basename(launch_file))
    with open(launch_file, 'wb') as f:
        output = template.render(c={'filename': os.path.basename(launch_file),
                                    'date': dt_string,
                                    'package_name': package_name,
                                    'rviz_collect_data': rviz_collect_data,
                                    'bag_file': bag_file_rel
                                    })
        f.write(output.encode('utf-8'))

    # --------------------------------------------------------------------------
    # Create the calibrate launch file
    # --------------------------------------------------------------------------
    launch_file = calibrate_launch_file
    print('Setting up ' + launch_file + ' ...')

    template = env.get_template(os.path.basename(launch_file))
    with open(launch_file, 'wb') as f:
        output = template.render(c={'filename': os.path.basename(launch_file),
                                    'date': dt_string,
                                    'package_name': package_name,
                                    'rviz_calibrate': rviz_calibrate
                                    })
        f.write(output.encode('utf-8'))
    # --------------------------------------------------------------------------
    # Create the dataset playback launch file
    # --------------------------------------------------------------------------
    launch_file = dataset_playback_launch_file
    print('Setting up ' + launch_file + ' ...')

    template = env.get_template(os.path.basename(launch_file))
    with open(launch_file, 'wb') as f:
        output = template.render(c={'filename': os.path.basename(launch_file),
                                    'date': dt_string,
                                    'package_name': package_name,
                                    'bag_file': bag_file_rel,
                                    'rviz_dataset_playback': rviz_dataset_playback
                                    })
        f.write(output.encode('utf-8'))
    # --------------------------------------------------------------------------
    # Check if modalities are properly created
    # --------------------------------------------------------------------------
    # TODO change lidar to lidar3d and lidar2d to lidar2d; change modality to modality
    for sensor_key in config['sensors']:
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        if topic in bag_topics:
            msg_type = bag_info[1][topic].msg_type
        elif topic_compressed in bag_topics:
            msg_type = bag_info[1][topic_compressed].msg_type
        if ('modality' not in config['sensors'][sensor_key]) or (
                config['sensors'][sensor_key]['modality'] not in ['rgb', 'depth', 'lidar3d', 'lidar2d']):
            print(
                Fore.YELLOW + 'Warning: Sensor ID not properly identified for sensor ' + sensor_key + ' with topic '
                + topic + "Sensor will be identified by message type." + Style.RESET_ALL)
            if msg_type == 'sensor_msgs/CompressedImage' or \
                    msg_type == 'sensor_msgs/Image':
                config['sensors'][sensor_key]['modality'] = 'rgb'
            elif msg_type == 'sensor_msgs/LaserScan':
                config['sensors'][sensor_key]['modality'] = 'lidar2d'
            elif msg_type == 'sensor_msgs/PointCloud2':
                config['sensors'][sensor_key]['modality'] = 'lidar3d'
            else:
                raise ValueError(
                    Fore.RED + 'Error: Cannot generate rviz configuration for sensor ' + sensor_key + ' with topic '
                    + topic + Style.RESET_ALL)

    # --------------------------------------------------------------------------
    # Create the rviz config core displays (used in several rviz config files)
    # --------------------------------------------------------------------------
    # TODO change rviz fixed_frame according to args['world_link']
    core_displays = []

    # Create grid, tf and robot model displays
    rendered = env.get_template('/rviz/Grid.rviz').render(c={'Reference_Frame': config['world_link']})
    core_displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    rendered = env.get_template('/rviz/TF.rviz').render(c={'Name': 'TF'})
    core_displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    rendered = env.get_template('/rviz/RobotModel.rviz').render(c={'Name': 'RobotModel'})
    core_displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # --------------------------------------------------------------------------
    # Create the rviz config file for the set_initial_estimate
    # --------------------------------------------------------------------------
    print('Setting up ' + rviz_set_initial_estimate + ' ...')
    rviz = yaml.load(open(rviz_file_template), Loader=yaml.SafeLoader)
    rviz['Visualization Manager']['Global Options']['Fixed Frame'] = config[
        'world_link']  # set fixed frame to world_link
    displays = deepcopy(core_displays)  # start with the core displays

    # Create interactive marker display for moving the sensors
    rendered = env.get_template('/rviz/InteractiveMarker.rviz').render(c={'Name': 'MoveSensors-InteractiveMarker',
                                                                          'Update_Topic': 'set_initial_estimate/update'}
                                                                       )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Generate rviz displays according to the sensor types
    for idx, sensor_key in enumerate(config['sensors']):
        color = atom_core.drawing.colormapToRVizColor(cm_sensors[idx, :])
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        # if topic in bag_topics:
        #     msg_type = bag_info[1][topic].msg_type
        # else:
        #     msg_type = bag_info[1][topic_compressed].msg_type
        modality = config['sensors'][sensor_key]['modality']

        print('\tGenerating rviz displays for sensor ' + sensor_key + ' with topic ' + topic + ' (' + modality + ')')

        # if msg_type == 'sensor_msgs/CompressedImage' or \
        #         msg_type == 'sensor_msgs/Image':  # add displays for camera sensor
        # TODO check if depth should be here or not
        if modality == 'rgb' or modality == 'depth':

            # Raw image
            rendered = env.get_template('/rviz/Image.rviz').render(c={'Name': sensor_key + '-Image',
                                                                      'Image_Topic': topic})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Camera
            rendered = env.get_template('/rviz/Camera.rviz').render(c={'Name': sensor_key + '-Camera',
                                                                       'Image_Topic': topic})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        # elif msg_type == 'sensor_msgs/LaserScan':
        elif modality == 'lidar2d':
            # Raw data
            rendered = env.get_template('/rviz/LaserScan.rviz').render(c={'Name': sensor_key + '-LaserScan',
                                                                          'Topic': topic,
                                                                          'Color': color})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        # elif msg_type == 'sensor_msgs/PointCloud2':
        elif modality == 'lidar3d':
            # Raw data
            rendered = env.get_template('/rviz/PointCloud2.rviz').render(c={'Name': sensor_key + '-PointCloud2',
                                                                            'Topic': topic,
                                                                            'Color': color,
                                                                            'Color_Transformer': 'FlatColor',
                                                                            'Style': 'Spheres',
                                                                            'Size__m_': 0.02,
                                                                            'Alpha': 1})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        else:
            print(Fore.YELLOW + 'Warning: Cannot generate rviz configuration for sensor ' + sensor_key + ' with topic '
                  + topic + ' (' + modality + ')' + Style.RESET_ALL)

    rviz['Visualization Manager']['Displays'] = displays
    yaml.dump(rviz, open(package_path + '/rviz/' + rviz_set_initial_estimate, 'w'))

    # --------------------------------------------------------------------------
    # Create the rviz config file for the dataset_playback
    # --------------------------------------------------------------------------
    print('Setting up ' + rviz_dataset_playback + ' ...')
    rviz = yaml.load(open(rviz_file_template), Loader=yaml.SafeLoader)
    rviz['Visualization Manager']['Global Options']['Fixed Frame'] = config[
        'world_link']  # set fixed frame to world_link
    displays = deepcopy(core_displays)  # start with the core displays

    rendered = env.get_template('/rviz/MarkerArray.rviz').render(c={'Name': 'Robot Meshes',
                                                                    'Marker_Topic': '/dataset_playback/robot_meshes'})
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Generate rviz displays according to the sensor types
    for idx, sensor_key in enumerate(config['sensors']):
        color = atom_core.drawing.colormapToRVizColor(cm_sensors[idx, :])
        topic = config['sensors'][sensor_key]['topic_name']
        modality = config['sensors'][sensor_key]['modality']

        print('\tGenerating rviz displays for sensor ' + sensor_key + ' with topic ' + topic + ' (' + modality + ')')

        # if msg_type == 'sensor_msgs/CompressedImage' or \
        #         msg_type == 'sensor_msgs/Image':  # add displays for camera sensor
        # TODO check if depth should be here or not
        if modality == 'rgb' or modality == 'depth':

            # Raw image
            rendered = env.get_template('/rviz/Image.rviz').render(c={'Name': sensor_key + '-Image',
                                                                      'Image_Topic': topic+'/labeled'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        # elif msg_type == 'sensor_msgs/LaserScan':
        elif modality == 'lidar2d':
            # Raw data
            rendered = env.get_template('/rviz/LaserScan.rviz').render(c={'Name': sensor_key + '-LaserScan',
                                                                          'Topic': topic,
                                                                          'Color': color})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        # elif msg_type == 'sensor_msgs/PointCloud2':
        elif modality == 'lidar3d':
            # Raw data
            rendered = env.get_template('/rviz/PointCloud2.rviz').render(c={'Name': sensor_key + '-PointCloud2',
                                                                            'Topic': sensor_key+'/points',
                                                                            'Color': color,
                                                                            'Color_Transformer': 'RGB8',
                                                                            'Style': 'Spheres',
                                                                            'Size__m_': 0.02,
                                                                            'Alpha': 1})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        else:
            print(Fore.YELLOW + 'Warning: Cannot generate rviz configuration for sensor ' + sensor_key + ' with topic '
                  + topic + ' (' + modality + ')' + Style.RESET_ALL)

    rviz['Visualization Manager']['Displays'] = displays
    yaml.dump(rviz, open(package_path + '/rviz/' + rviz_dataset_playback, 'w'))

    # --------------------------------------------------------------------------
    # Create the rviz config file for the collect_data
    # --------------------------------------------------------------------------
    print('Setting up ' + rviz_collect_data + ' ...')
    rviz = yaml.load(open(rviz_file_template), Loader=yaml.SafeLoader)
    rviz['Visualization Manager']['Global Options']['Fixed Frame'] = config[
        'world_link']  # set fixed frame to world_link
    displays = deepcopy(core_displays)  # start with the core displays

    # Add interactive maker display to handle sensor manual labelling
    rendered = env.get_template('/rviz/InteractiveMarker.rviz').render(
        c={'Name': 'ManualDataLabeler-InteractiveMarkers',
           'Update_Topic': 'data_labeler/update'}
    )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))
    # TODO this will be the menu (only one)

    depth = 0
    # Generate rviz displays according to the sensor types
    for idx, sensor_key in enumerate(config['sensors']):
        color = atom_core.drawing.colormapToRVizColor(cm_sensors[idx, :])
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        # if topic in bag_topics:
        #     msg_type = bag_info[1][topic].msg_type
        # else:
        #     msg_type = bag_info[1][topic_compressed].msg_type
        modality = config['sensors'][sensor_key]['modality']

        print('\tGenerating rviz displays for sensor ' + sensor_key + ' with topic ' + topic + ' (' + modality + ')')

        # if msg_type == 'sensor_msgs/CompressedImage' or msg_type == 'sensor_msgs/Image':  # displays for camera sensor
        # TODO check if depth should be here or separated
        if modality == 'rgb':
            # Image
            rendered = env.get_template('/rviz/Image.rviz').render(c={'Name': sensor_key + '-Labels' + '-Image',
                                                                      'Image_Topic': topic + '/labeled'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Camera
            rendered = env.get_template('/rviz/Camera.rviz').render(c={'Name': sensor_key + '-Camera',
                                                                       'Image_Topic': topic})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        elif modality == 'depth':
            depth += 1
            rendered = env.get_template('/rviz/Image.rviz').render(c={'Name': sensor_key + '-Labels' + '-Image',
                                                                      'Image_Topic': topic + '/labeled'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Camera
            rendered = env.get_template('/rviz/Camera.rviz').render(c={'Name': sensor_key + '-Camera',
                                                                       'Image_Topic': topic})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            rendered = env.get_template('/rviz/InteractiveMarker.rviz').render(
                c={'Name': sensor_key + '-ManualDataLabeler-InteractiveMarkers',
                   'Update_Topic': sensor_key + '/data_labeler/update'}
            )
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Frustum
            rendered = env.get_template('/rviz/MarkerArray.rviz').render(c={'Name': sensor_key + '-Frustum',
                                                                            'Marker_Topic': sensor_key + '/frustum'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        # elif msg_type == 'sensor_msgs/LaserScan':
        elif modality == 'lidar2d':
            rendered = env.get_template('/rviz/LaserScan.rviz').render(c={'Name': sensor_key + '-LaserScan',
                                                                          'Topic': topic,
                                                                          'Color': color})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Labels
            rendered = env.get_template('/rviz/PointCloud2.rviz').render(c={'Name': sensor_key + '-Labels-PointCloud2',
                                                                            'Topic': topic + '/labeled',
                                                                            'Color': color,
                                                                            'Color_Transformer': 'FlatColor',
                                                                            'Style': 'Spheres',
                                                                            'Size__m_': 0.2,
                                                                            'Alpha': 0.05})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # # TODO Add markers to display data clusters

            rendered = env.get_template('/rviz/InteractiveMarker.rviz').render(
                c={'Name': sensor_key + '-ManualDataLabeler-InteractiveMarkers',
                   'Update_Topic': sensor_key + '/data_labeler/update'}
            )
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        # elif msg_type == 'sensor_msgs/PointCloud2':
        elif modality == 'lidar3d':
            # Raw data
            rendered = env.get_template('/rviz/PointCloud2.rviz').render(c={'Name': sensor_key + '-PointCloud2',
                                                                            'Topic': topic,
                                                                            'Color': color,
                                                                            'Color_Transformer': 'FlatColor',
                                                                            'Style': 'Spheres',
                                                                            'Size__m_': 0.02,
                                                                            'Alpha': 1})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Labeled data
            rendered = env.get_template('/rviz/PointCloud2.rviz').render(c={'Name': sensor_key + '-Labels-PointCloud2',
                                                                            'Topic': topic + '/labeled',
                                                                            'Color': color,
                                                                            'Color_Transformer': 'FlatColor',
                                                                            'Style': 'Spheres',
                                                                            'Size__m_': 0.2,
                                                                            'Alpha': 0.05})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            # Interactive marker for the labeler
            rendered = env.get_template('/rviz/InteractiveMarker.rviz').render(
                c={'Name': sensor_key + '-ManualDataLabeler-InteractiveMarkers',
                   'Update_Topic': sensor_key + '/data_labeler/update'}
            )
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        else:
            print(Fore.YELLOW + 'Warning: Cannot generate rviz configuration for sensor ' + sensor_key + ' with topic '
                  + topic + ' (' + modality + ')' + Style.RESET_ALL)

    if depth != 0:
        # rendered = env.get_template('/rviz/MarkerArray.rviz').render(
        #     c={'Name': 'FrustumVisualizationDepthSensors',
        #        'Marker_Topic': '/sensor_frustum'})
        # displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))
        pass

    rviz['Visualization Manager']['Displays'] = displays
    yaml.dump(rviz, open(package_path + '/rviz/' + rviz_collect_data, 'w'))

    # --------------------------------------------------------------------------
    # Create the rviz config file for the calibrate
    # --------------------------------------------------------------------------
    print('Setting up ' + rviz_calibrate + ' ...')
    rviz = yaml.load(open(rviz_file_template), Loader=yaml.SafeLoader)
    rviz['Visualization Manager']['Global Options']['Fixed Frame'] = config[
        'world_link']  # set fixed frame to world_link
    displays = deepcopy(core_displays)  # start with the core displays
    displays.pop()  # remove the last item, which is the robot model

    # Add interactive maker display for showing robot meshes
    rendered = env.get_template('/rviz/MarkerArray.rviz').render(
        c={'Name': 'RobotMeshes-MarkerArray',
           'Marker_Topic': 'calibrate/robot_meshes'}
    )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Add a maker array display for showing the patterns
    rendered = env.get_template('/rviz/MarkerArray.rviz').render(
        c={'Name': 'Patterns-MarkerArray',
           'Marker_Topic': 'calibrate/patterns'}
    )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Add a maker array display for miscellaneous information
    rendered = env.get_template('/rviz/MarkerArray.rviz').render(
        c={'Name': 'Miscellaneous-MarkerArray',
           'Marker_Topic': 'calibrate/Miscellaneous'}
    )
    displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Check if 2d lidars exist, if so add laser beams marker
    modalitys = []
    for idx, sensor_key in enumerate(config['sensors']):
        modality = config['sensors'][sensor_key]['modality']
        modalitys.append(modality)

    if 'lidar2d' in modalitys:  # we have 2D lidar data, add laser beams marker
        # Add interactive maker display for showing laser beams
        rendered = env.get_template('/rviz/MarkerArray.rviz').render(
            c={'Name': 'LaserBeams-MarkerArray',
               'Marker_Topic': 'calibrate/LaserBeams'}
        )
        displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    # Generate rviz displays according to the sensor types
    for idx, sensor_key in enumerate(config['sensors']):
        color = atom_core.drawing.colormapToRVizColor(cm_sensors[idx, :])
        topic = config['sensors'][sensor_key]['topic_name']
        topic_compressed = topic + '/compressed'
        # if topic in bag_topics:
        #     msg_type = bag_info[1][topic].msg_type
        # else:
        #     msg_type = bag_info[1][topic_compressed].msg_type
        modality = config['sensors'][sensor_key]['modality']

        print('\tGenerating rviz displays for sensor ' + sensor_key + ' with topic ' + topic + ' (' + modality + ')')
        # TODO check if depth should be here or separated
        if modality == 'rgb':  # displays for camera sensor

            # Image
            rendered = env.get_template('/rviz/Image.rviz').render(
                c={'Name': sensor_key + '-Labels' + '-Image', 'Image_Topic': 'calibrate/c0' + topic + '/labeled'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        elif modality == "depth":
            rendered = env.get_template('/rviz/MarkerArray.rviz').render(
                c={'Name': sensor_key + '-LabeledData', 'Marker_Topic': 'calibrate/' + sensor_key + '/labeled_data'}
            )
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

            rendered = env.get_template('/rviz/Image.rviz').render(
                c={'Name': sensor_key + '-Labels' + '-Image', 'Image_Topic': 'calibrate/c0' + topic + '/labeled'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        elif modality == 'lidar2d':
            # Labelled data
            rendered = env.get_template('/rviz/MarkerArray.rviz').render(
                c={'Name': sensor_key + '-LabeledData', 'Marker_Topic': 'calibrate/' + sensor_key + '/labeled_data'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

        elif modality == 'lidar3d':
            # Labelled data
            rendered = env.get_template('/rviz/MarkerArray.rviz').render(
                c={'Name': sensor_key + '-LabeledData', 'Marker_Topic': 'calibrate/' + sensor_key + '/labeled_data'})
            displays.append(yaml.load(rendered, Loader=yaml.SafeLoader))

    rviz['Visualization Manager']['Displays'] = displays
    yaml.dump(rviz, open(package_path + '/rviz/' + rviz_calibrate, 'w'))

    # Print final report
    print(
        '\nCreated a calibration configuration summary. Use it to see if the calibration is well set up. Located at:\n'
        + package_path + '/calibration/summary.pdf')
    print('\nSuccessfully configured calibration package ' + Fore.BLUE + package_name + Style.RESET_ALL +
          '. You can use the launch files:')
    print(Fore.BLUE + 'roslaunch ' + package_name + ' ' + os.path.basename(playbag_launch_file) + Style.RESET_ALL)
    print(Fore.BLUE + 'roslaunch ' + package_name + ' ' + os.path.basename(set_initial_estimate_launch_file) +
          Style.RESET_ALL)
    print(Fore.BLUE + 'roslaunch ' + package_name + ' ' + os.path.basename(data_collection_launch_file) +
          Style.RESET_ALL)
    print(Fore.BLUE + 'roslaunch ' + package_name + ' ' + os.path.basename(calibrate_launch_file) + Style.RESET_ALL)
